{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2380bcc2",
   "metadata": {},
   "source": [
    "# WEBSCRAPING - ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354b995",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n",
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n",
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n",
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n",
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n",
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n",
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code\n",
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68eddee",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist \n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4464f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,InvalidArgumentException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911b5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8868d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening site\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb44f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# creating empty list to store data\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_date = []\n",
    "Views = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3855f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scraping whole data in one step \n",
    "rank = [] # to store whole data then i will separate them\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//td')[2:]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('-')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8d388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extracting rank from the list contining whole info\n",
    "Rank = rank[0::6][0:30]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c4bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extractin name of video\n",
    "Name = rank[1::6][0:30]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ca94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extracting Artist Name\n",
    "Artist = rank[2::6][0:30]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1a1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extracting views\n",
    "Views = rank[3::6][0:30]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637a87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting upload date\n",
    "Upload_date = rank[4::6][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171e63cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most viewed videos on YouTube from Wikipedia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>VIDEO NAME</th>\n",
       "      <th>ATRIST</th>\n",
       "      <th>VIEWS(BILLIONS)</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.58</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.99</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.50</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.83</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.68</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[16]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.68</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.96</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.73</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.69</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.58</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.50</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.11</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.77</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.67</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.67</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.60</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.56</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.41</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.37</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.36</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.34</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.32</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.29</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.28</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Lean On\"[45]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.28</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.27</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.22</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.19</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                                       VIDEO NAME  \\\n",
       "1    1.                            \"Baby Shark Dance\"[3]   \n",
       "2    2.                                   \"Despacito\"[6]   \n",
       "3    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "4    4.                               \"Shape of You\"[13]   \n",
       "5    5.                                  \"Bath Song\"[15]   \n",
       "6    6.                              \"See You Again\"[16]   \n",
       "7    7.                \"Phonics Song with Two Words\"[21]   \n",
       "8    8.                                \"Uptown Funk\"[22]   \n",
       "9    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "10  10.                              \"Gangnam Style\"[24]   \n",
       "11  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "12  12.                          \"Wheels on the Bus\"[30]   \n",
       "13  13.                             \"Dame Tu Cosita\"[31]   \n",
       "14  14.                                      \"Sugar\"[32]   \n",
       "15  15.                                       \"Roar\"[33]   \n",
       "16  16.                             \"Counting Stars\"[34]   \n",
       "17  17.                                      \"Sorry\"[35]   \n",
       "18  18.                                     \"Axel F\"[36]   \n",
       "19  18.                          \"Thinking Out Loud\"[37]   \n",
       "20  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "21  21.                                 \"Dark Horse\"[39]   \n",
       "22  22.                                      \"Faded\"[40]   \n",
       "23  23.                             \"Girls Like You\"[41]   \n",
       "24  24.                                 \"Let Her Go\"[42]   \n",
       "25  25.                                   \"Bailando\"[43]   \n",
       "26  26.                                    \"Perfect\"[44]   \n",
       "27  27.                                    \"Lean On\"[45]   \n",
       "28  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "29  29.                               \"Shake It Off\"[47]   \n",
       "30  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           ATRIST VIEWS(BILLIONS)  \\\n",
       "1     Pinkfong Baby Shark - Kids' Songs & Stories           11.58   \n",
       "2                                      Luis Fonsi            7.99   \n",
       "3                                     LooLoo Kids            6.50   \n",
       "4                                      Ed Sheeran            5.83   \n",
       "5                      Cocomelon – Nursery Rhymes            5.68   \n",
       "6                                     Wiz Khalifa            5.68   \n",
       "7                                       ChuChu TV            4.96   \n",
       "8                                     Mark Ronson            4.73   \n",
       "9                                     Miroshka TV            4.69   \n",
       "10                                            Psy            4.58   \n",
       "11                                     Get Movies            4.51   \n",
       "12                     Cocomelon – Nursery Rhymes            4.50   \n",
       "13                                      El Chombo            4.11   \n",
       "14                                       Maroon 5            3.77   \n",
       "15                                     Katy Perry            3.67   \n",
       "16                                    OneRepublic            3.67   \n",
       "17                                  Justin Bieber            3.60   \n",
       "18                                     Crazy Frog            3.56   \n",
       "19                                     Ed Sheeran            3.51   \n",
       "20                     Cocomelon – Nursery Rhymes            3.41   \n",
       "21                                     Katy Perry            3.37   \n",
       "22                                    Alan Walker            3.36   \n",
       "23                                       Maroon 5            3.34   \n",
       "24                                      Passenger            3.32   \n",
       "25                               Enrique Iglesias            3.29   \n",
       "26                                     Ed Sheeran            3.28   \n",
       "27                                    Major Lazer            3.28   \n",
       "28                                        Shakira            3.27   \n",
       "29                                   Taylor Swift            3.22   \n",
       "30  Kiddiestv Hindi – Nursery Rhymes & Kids Songs            3.19   \n",
       "\n",
       "          UPLOAD DATE  \n",
       "1       June 17, 2016  \n",
       "2    January 12, 2017  \n",
       "3     October 8, 2016  \n",
       "4    January 30, 2017  \n",
       "5         May 2, 2018  \n",
       "6       April 6, 2015  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12       May 24, 2018  \n",
       "13      April 5, 2018  \n",
       "14   January 14, 2015  \n",
       "15  September 5, 2013  \n",
       "16       May 31, 2013  \n",
       "17   October 22, 2015  \n",
       "18      June 16, 2009  \n",
       "19    October 7, 2014  \n",
       "20      June 25, 2018  \n",
       "21  February 20, 2014  \n",
       "22   December 3, 2015  \n",
       "23       May 31, 2018  \n",
       "24      July 25, 2012  \n",
       "25     April 11, 2014  \n",
       "26   November 9, 2017  \n",
       "27     March 22, 2015  \n",
       "28       June 4, 2010  \n",
       "29    August 18, 2014  \n",
       "30   January 26, 2018  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"RANK\":Rank,\"VIDEO NAME\":Name,\"ATRIST\":Artist,\"VIEWS(BILLIONS)\":Views,\"UPLOAD DATE\":Upload_date},index=list(range(1,len(Upload_date)+1)))\n",
    "print(\"Most viewed videos on YouTube from Wikipedia\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc57aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52304316",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a60d3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e06639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5629f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get webpage\n",
    "url=(\"https://www.bcci.tv/\")\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad7efc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on menu\n",
    "button= driver.find_element(By.XPATH,'//span[@class = \"menu-icon__line menu-icon__line-right\"]').get_attribute('href')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd8c980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting International\n",
    "International= driver.find_element(By.XPATH,'//a[@class = \"nav-link \"]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f88d5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on dropdown\n",
    "Select= driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[1]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed8b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting ODI\n",
    "OdI= driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[2]/div[3]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "144af956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 6 6 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Eden Park, Auckland,Match Centre</td>\n",
       "      <td>25 NOV 2022</td>\n",
       "      <td>7:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Seddon Park, Hamilton,Match Centre</td>\n",
       "      <td>27 NOV 2022</td>\n",
       "      <td>7:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Hagley Oval, Christchurch,Match Centre</td>\n",
       "      <td>30 NOV 2022</td>\n",
       "      <td>7:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka,...</td>\n",
       "      <td>4 DEC 2022</td>\n",
       "      <td>12:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka,...</td>\n",
       "      <td>7 DEC 2022</td>\n",
       "      <td>12:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka,...</td>\n",
       "      <td>10 DEC 2022</td>\n",
       "      <td>12:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Match_title    Series  \\\n",
       "0  INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23  1st ODI    \n",
       "1  INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23  2nd ODI    \n",
       "2  INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23  3rd ODI    \n",
       "3   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23  1st ODI    \n",
       "4   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23  2nd ODI    \n",
       "5   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23  3rd ODI    \n",
       "\n",
       "                                               Place         Date  \\\n",
       "0                   Eden Park, Auckland,Match Centre  25 NOV 2022   \n",
       "1                 Seddon Park, Hamilton,Match Centre  27 NOV 2022   \n",
       "2             Hagley Oval, Christchurch,Match Centre  30 NOV 2022   \n",
       "3   Shere Bangla National Stadium, Mirpur, Dhaka,...   4 DEC 2022   \n",
       "4   Shere Bangla National Stadium, Mirpur, Dhaka,...   7 DEC 2022   \n",
       "5   Shere Bangla National Stadium, Mirpur, Dhaka,...  10 DEC 2022   \n",
       "\n",
       "           Time  \n",
       "0   7:00 AM IST  \n",
       "1   7:00 AM IST  \n",
       "2   7:00 AM IST  \n",
       "3  12:30 PM IST  \n",
       "4  12:30 PM IST  \n",
       "5  12:30 PM IST  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Match_title= []\n",
    "Series= []\n",
    "Place= []\n",
    "Date= []\n",
    "Time= []\n",
    "\n",
    "#scraping Match Title\n",
    "try:\n",
    "    Match_title_tag= driver.find_elements(By.XPATH,\"//div[@class='fixture-card-top']/h5[2]\")\n",
    "    for i in Match_title_tag:\n",
    "        Match_title.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Match_title.append(\"--\")\n",
    "\n",
    "#scraping Series\n",
    "try:\n",
    "    Series_tag= driver.find_elements(By.XPATH,\"//div[@class='fixture-card-bottom']\")\n",
    "    for i in Series_tag:\n",
    "        Series.append(i.text.split(\"-\")[0])\n",
    "except NoSuchElementException as e:\n",
    "    Series.append(\"--\")\n",
    "    \n",
    "#scraping Place\n",
    "try:\n",
    "    Place_tag= driver.find_elements(By.XPATH,\"//div[@class='fixture-card-bottom']\")\n",
    "    for i in Place_tag:\n",
    "        Place.append(i.text.split(\"-\")[1].replace(\"\\n\",\",\"))\n",
    "except NoSuchElementException as e:\n",
    "    Place.append(\"--\") \n",
    "\n",
    "#scraping Date\n",
    "try:\n",
    "    Date_tag= driver.find_elements(By.XPATH,\"//div[@class='match-card-left match-schedule']\")\n",
    "    for i in Date_tag:\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Date.append(\"--\")\n",
    "\n",
    "#scraping Time   \n",
    "try:\n",
    "    Time_tag= driver.find_elements(By.XPATH,\"//div[@class='match-card-right match-schedule ']\")\n",
    "    for i in Time_tag:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Time.append(\"--\")\n",
    "\n",
    "#printing length\n",
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))\n",
    "\n",
    "#creating Dataframe\n",
    "international_fixtures=pd.DataFrame({\"Match_title\":Match_title,\"Series\":Series,\"Place\":Place,\"Date\":Date,\"Time\":Time})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e2e60",
   "metadata": {},
   "source": [
    "\n",
    "Q3. Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/ You need to find following details:\n",
    "\n",
    "A) Name \n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27581fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba041f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "374f26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Selenium option\n",
    "\n",
    "selenium=driver.find_element(By.XPATH,'//div[@class=\"featured-box cloumnsize1\"]/ul[1]/li[3]/a')\n",
    "try:\n",
    "    selenium.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(selenium.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0555bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Selenium exception\n",
    "\n",
    "exceptation =driver.find_element(By.XPATH,'//*[@id=\"post-193\"]/div/div/table[5]/tbody/tr[34]/td[1]/a')\n",
    "try:\n",
    "    exceptation.click()\n",
    "    time.sleep(2)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(exceptation.get_attribute('href'))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fcf80140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list to store all the scrapped result\n",
    "name =[]\n",
    "description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0af00635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting name and description of exception\n",
    "all_info=[]\n",
    "try:\n",
    "    all_tags =driver.find_elements(By.XPATH,'//div[@class=\"entry-content single-content\"]/p')\n",
    "    for i in all_tags:\n",
    "        all_info.append(i.text.split(\":\"))\n",
    "except NoSuchElementException:\n",
    "    all_info.append('--')\n",
    "all_info1= all_info[:41]\n",
    "\n",
    "jj=[]\n",
    "for i in all_info1:\n",
    "    for j in i:\n",
    "        jj.append(j)\n",
    "        \n",
    "\n",
    "for i in range(0, len(jj)):\n",
    "    if i % 2 ==0:\n",
    "        name.append(jj[i])\n",
    "\n",
    "for i in range(0, len(jj)):\n",
    "    if i % 2 ==1:\n",
    "        description.append(jj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b250bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(name))\n",
    "print(len(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d74112eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of selenium exception from guru99.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3. NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4. NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5. NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6. NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7. StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8. SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9. TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10. WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11. ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12. ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13. ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14. ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15. ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16. ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17. ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18. InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19. InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20. InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21. InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22. InvalidElementStateException</td>\n",
       "      <td>It occurs when command can’t be finished when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23. InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24. InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25. JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26. JsonException</td>\n",
       "      <td>It occurs when you afford to get the session ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27. NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28. MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29. NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30. NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31. NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32. RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33. ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34. SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35. UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36. UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37. UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an aler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38. UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39. UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40. UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41. UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver doesn’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "Sr. No.                                            \n",
       "1                  1. ElementNotVisibleException   \n",
       "2               2. ElementNotSelectableException   \n",
       "3                      3. NoSuchElementException   \n",
       "4                        4. NoSuchFrameException   \n",
       "5                     5. NoAlertPresentException   \n",
       "6                       6. NoSuchWindowException   \n",
       "7              7. StaleElementReferenceException   \n",
       "8                    8. SessionNotFoundException   \n",
       "9                            9. TimeoutException   \n",
       "10                        10. WebDriverException   \n",
       "11                 11. ConnectionClosedException   \n",
       "12          12. ElementClickInterceptedException   \n",
       "13           13. ElementNotInteractableException   \n",
       "14                  14. ErrorInResponseException   \n",
       "15       15. ErrorHandler.UnknownServerException   \n",
       "16              16. ImeActivationFailedException   \n",
       "17                  17. ImeNotAvailableException   \n",
       "18              18. InsecureCertificateException   \n",
       "19                  19. InvalidArgumentException   \n",
       "20              20. InvalidCookieDomainException   \n",
       "21               21. InvalidCoordinatesException   \n",
       "22              22. InvalidElementStateException   \n",
       "23                 23. InvalidSessionIdException   \n",
       "24            24. InvalidSwitchToTargetException   \n",
       "25                       25. JavascriptException   \n",
       "26                             26. JsonException   \n",
       "27                  27. NoSuchAttributeException   \n",
       "28            28. MoveTargetOutOfBoundsException   \n",
       "29                    29. NoSuchContextException   \n",
       "30                     30. NoSuchCookieException   \n",
       "31                         31. NotFoundException   \n",
       "32               32. RemoteDriverServerException   \n",
       "33                       33. ScreenshotException   \n",
       "34                34. SessionNotCreatedException   \n",
       "35                35. UnableToSetCookieException   \n",
       "36                36. UnexpectedTagNameException   \n",
       "37                   37. UnhandledAlertException   \n",
       "38           38. UnexpectedAlertPresentException   \n",
       "39                    39. UnknownMethodException   \n",
       "40               40. UnreachableBrowserException   \n",
       "41               41. UnsupportedCommandException   \n",
       "\n",
       "                                               Description  \n",
       "Sr. No.                                                     \n",
       "1         This type of Selenium exception occurs when a...  \n",
       "2         This Selenium exception occurs when an elemen...  \n",
       "3         This Exception occurs if an element could not...  \n",
       "4         This Exception occurs if the frame target to ...  \n",
       "5         This Exception occurs when you switch to no p...  \n",
       "6         This Exception occurs if the window target to...  \n",
       "7         This Selenium exception occurs happens when t...  \n",
       "8         The WebDriver is acting after you quit the br...  \n",
       "9         Thrown when there is not enough time for a co...  \n",
       "10        This Exception takes place when the WebDriver...  \n",
       "11        This type of Exception takes place when there...  \n",
       "12        The command may not be completed as the eleme...  \n",
       "13        This Selenium exception is thrown when any el...  \n",
       "14        This happens while interacting with the Firef...  \n",
       "15        Exception is used as a placeholder in case if...  \n",
       "16        This expectation will occur when IME engine a...  \n",
       "17         It takes place when IME support is unavailable.  \n",
       "18        Navigation made the user agent to hit a certi...  \n",
       "19        It occurs when an argument does not belong to...  \n",
       "20        This happens when you try to add a cookie und...  \n",
       "21        This type of Exception matches an interacting...  \n",
       "22        It occurs when command can’t be finished when...  \n",
       "23        This Exception took place when the given sess...  \n",
       "24        This occurs when the frame or window target t...  \n",
       "25        This issue occurs while executing JavaScript ...  \n",
       "26        It occurs when you afford to get the session ...  \n",
       "27        This kind of Exception occurs when the attrib...  \n",
       "28        It takes place if the target provided to the ...  \n",
       "29                ContextAware does mobile device testing.  \n",
       "30        This Exception occurs when no cookie matching...  \n",
       "31        This Exception is a subclass of WebDriverExce...  \n",
       "32        This Selenium exception is thrown when the se...  \n",
       "33                 It is not possible to capture a screen.  \n",
       "34        It happens when a new session could not be su...  \n",
       "35        This occurs if a driver is unable to set a co...  \n",
       "36        Happens if a support class did not get a web ...  \n",
       "37        This expectation occurs when there is an aler...  \n",
       "38        It occurs when there is the appearance of an ...  \n",
       "39        This Exception happens when the requested com...  \n",
       "40        This Exception occurs only when the browser i...  \n",
       "41        This occurs when remote WebDriver doesn’t sen...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,description ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Name','Description'],\n",
    "    index=pd.RangeIndex(start=1, stop=42, name='Sr. No.'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of selenium exception from guru99.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80b013",
   "metadata": {},
   "source": [
    "\n",
    "Q4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: \n",
    "\n",
    "A) Rank \n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(19-20)\n",
    "\n",
    "D) GSDP (18-19)\n",
    "\n",
    "E) Share (18-19\n",
    "\n",
    ") F) GDP (billion)\n",
    "\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5d5a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f3ec0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b227c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on ecomony tab\n",
    "\n",
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/button')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))  \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0861b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Clicking on India from economy tab\n",
    "state = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6424f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian state\n",
    "\n",
    "state = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66e3c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store all the scrapped result\n",
    "rank =[]\n",
    "state =[]\n",
    "gsdp_19_20=[]\n",
    "gsdp_18_19 =[]\n",
    "share_18_19 =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b81c7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    rank_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank_tags :\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('NA')\n",
    "    \n",
    "# Extracting state name\n",
    "try:\n",
    "    state_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state_tags:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20\n",
    "try:\n",
    "    gsdp_19_20_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gsdp_19_20_tags:\n",
    "        gsdp_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19\n",
    "try:\n",
    "    gsdp_18_19_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gsdp_18_19_tags:\n",
    "        gsdp_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_18_19.append('NA')\n",
    "    \n",
    "# Extracting Share 18_19\n",
    "try:\n",
    "    share_18_19_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share_18_19_tags:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append('NA')\n",
    "    \n",
    "# Extracting GDP\n",
    "try:\n",
    "    GDP_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in GDP_tags:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af6ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank))\n",
    "print(len(state))\n",
    "print(len(gsdp_19_20))\n",
    "print(len(gsdp_18_19))\n",
    "print(len(share_18_19))\n",
    "print(len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f159ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of State-wise GDP of India from statisticstime.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                      State GSDP_19_20 GSDP_18_19 Share_18_19  \\\n",
       "Sr. No.                                                                     \n",
       "1          1                Maharashtra          -  2,632,792      13.94%   \n",
       "2          2                 Tamil Nadu  1,845,853  1,630,208       8.63%   \n",
       "3          3              Uttar Pradesh  1,687,818  1,584,764       8.39%   \n",
       "4          4                    Gujarat          -  1,502,899       7.96%   \n",
       "5          5                  Karnataka  1,631,977  1,493,127       7.91%   \n",
       "6          6                West Bengal  1,253,832  1,089,898       5.77%   \n",
       "7          7                  Rajasthan  1,020,989    942,586       4.99%   \n",
       "8          8             Andhra Pradesh    972,782    862,957       4.57%   \n",
       "9          9                  Telangana    969,604    861,031       4.56%   \n",
       "10        10             Madhya Pradesh    906,672    809,592       4.29%   \n",
       "11        11                     Kerala          -    781,653       4.14%   \n",
       "12        12                      Delhi    856,112    774,870       4.10%   \n",
       "13        13                    Haryana    831,610    734,163       3.89%   \n",
       "14        14                      Bihar    611,804    530,363       2.81%   \n",
       "15        15                     Punjab    574,760    526,376       2.79%   \n",
       "16        16                     Odisha    521,275    487,805       2.58%   \n",
       "17        17                      Assam          -    315,881       1.67%   \n",
       "18        18               Chhattisgarh    329,180    304,063       1.61%   \n",
       "19        19                  Jharkhand    328,598    297,204       1.57%   \n",
       "20        20                Uttarakhand          -    245,895       1.30%   \n",
       "21        21            Jammu & Kashmir          -    155,956       0.83%   \n",
       "22        22           Himachal Pradesh    165,472    153,845       0.81%   \n",
       "23        23                        Goa     80,449     73,170       0.39%   \n",
       "24        24                    Tripura     55,984     49,845       0.26%   \n",
       "25        25                 Chandigarh          -     42,114       0.22%   \n",
       "26        26                 Puducherry     38,253     34,433       0.18%   \n",
       "27        27                  Meghalaya     36,572     33,481       0.18%   \n",
       "28        28                     Sikkim     32,496     28,723       0.15%   \n",
       "29        29                    Manipur     31,790     27,870       0.15%   \n",
       "30        30                   Nagaland          -     27,283       0.14%   \n",
       "31        31          Arunachal Pradesh          -     24,603       0.13%   \n",
       "32        32                    Mizoram     26,503     22,287       0.12%   \n",
       "33        33  Andaman & Nicobar Islands          -          -           -   \n",
       "\n",
       "             GDP  \n",
       "Sr. No.           \n",
       "1        399.921  \n",
       "2        247.629  \n",
       "3        240.726  \n",
       "4        228.290  \n",
       "5        226.806  \n",
       "6        165.556  \n",
       "7        143.179  \n",
       "8        131.083  \n",
       "9        130.791  \n",
       "10       122.977  \n",
       "11       118.733  \n",
       "12       117.703  \n",
       "13       111.519  \n",
       "14        80.562  \n",
       "15        79.957  \n",
       "16        74.098  \n",
       "17        47.982  \n",
       "18        46.187  \n",
       "19        45.145  \n",
       "20        37.351  \n",
       "21        23.690  \n",
       "22        23.369  \n",
       "23        11.115  \n",
       "24         7.571  \n",
       "25         6.397  \n",
       "26         5.230  \n",
       "27         5.086  \n",
       "28         4.363  \n",
       "29         4.233  \n",
       "30         4.144  \n",
       "31         3.737  \n",
       "32         3.385  \n",
       "33             -  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(rank, state,gsdp_19_20, gsdp_18_19,share_18_19 , GDP))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Rank', 'State', 'GSDP_19_20','GSDP_18_19','Share_18_19' , 'GDP'],\n",
    "                index=pd.RangeIndex(start=1, stop=34, name='Sr. No.'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of State-wise GDP of India from statisticstime.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3d5d5",
   "metadata": {},
   "source": [
    "\n",
    "Q5. Scrape the details of trending repositories on Github.com. Url = https://github.com/You have to find the following details:\n",
    "\n",
    "A) Repository title \n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count \n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846e7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary librabies for webscraping with selenium\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2985f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa1250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://github.com/You\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47693c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on button tab\n",
    "\n",
    "button =driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "driver.get(button.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d750ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "title=[]\n",
    "description=[]\n",
    "count =[]\n",
    "language =[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5830d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Share 18_19\n",
    "try:\n",
    "    title_tags =driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title_tags:\n",
    "        title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    title.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fc4dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daec7d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting URL\n",
    "\n",
    "try:\n",
    "    url_tags =driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "    for i in url_tags:\n",
    "        url.append(i.get_attribute(\"href\"))\n",
    "except NoSuchElementException:\n",
    "    url.append('NA')\n",
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fcbb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        description_tags=driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[1]/div/p')\n",
    "        description.append(description_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        description.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a275a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0f06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        count_tags=driver.find_element(By.XPATH, \"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        count.append(count_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        count.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ebdbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c92fb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        language_tag =driver.find_elements(By.XPATH,\"//li[@class='d-inline']//a//span[1]\")\n",
    "        if language_tag:\n",
    "            for j in language_tag:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        language.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d875ccc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(language)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0122104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of trending repositories on Github.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Count</th>\n",
       "      <th>Language</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dudykr / stc</td>\n",
       "      <td>Speedy TypeScript type checker</td>\n",
       "      <td>4</td>\n",
       "      <td>[Rust]</td>\n",
       "      <td>https://github.com/dudykr/stc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charmbracelet / vhs</td>\n",
       "      <td>Your CLI home video recorder 📼</td>\n",
       "      <td>8</td>\n",
       "      <td>[Go, Dockerfile]</td>\n",
       "      <td>https://github.com/charmbracelet/vhs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simeydotme / pokemon-cards-css</td>\n",
       "      <td>A collection of advanced CSS styles to create ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Svelte, CSS, JavaScript, HTML]</td>\n",
       "      <td>https://github.com/simeydotme/pokemon-cards-css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocornut / imgui</td>\n",
       "      <td>Dear ImGui: Bloat-free Graphical User interfac...</td>\n",
       "      <td>305</td>\n",
       "      <td>[C++, C, Objective-C++, Objective-C, GLSL, GDB]</td>\n",
       "      <td>https://github.com/ocornut/imgui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acmesh-official / acme.sh</td>\n",
       "      <td>A pure Unix shell script implementing ACME cli...</td>\n",
       "      <td>407</td>\n",
       "      <td>[Shell, Dockerfile]</td>\n",
       "      <td>https://github.com/acmesh-official/acme.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mastodon / mastodon</td>\n",
       "      <td>Your self-hosted, globally interconnected micr...</td>\n",
       "      <td>687</td>\n",
       "      <td>[Ruby, JavaScript, SCSS, Haml, HTML, Dockerfile]</td>\n",
       "      <td>https://github.com/mastodon/mastodon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alvaroreis / bolsonaro2turno</td>\n",
       "      <td>Gere seu flyer personalizado com seu nome de a...</td>\n",
       "      <td>NA</td>\n",
       "      <td>[HTML, JavaScript, CSS]</td>\n",
       "      <td>https://github.com/alvaroreis/bolsonaro2turno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ossu / computer-science</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>126</td>\n",
       "      <td>[NA]</td>\n",
       "      <td>https://github.com/ossu/computer-science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faridrashidi / kaggle-solutions</td>\n",
       "      <td>🏅 Collection of Kaggle Solutions and Ideas 🏅</td>\n",
       "      <td>2</td>\n",
       "      <td>[HTML]</td>\n",
       "      <td>https://github.com/faridrashidi/kaggle-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jellyfin / jellyfin</td>\n",
       "      <td>The Free Software Media System</td>\n",
       "      <td>793</td>\n",
       "      <td>[C#]</td>\n",
       "      <td>https://github.com/jellyfin/jellyfin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shadcn / taxonomy</td>\n",
       "      <td>An open source application built using the new...</td>\n",
       "      <td>NA</td>\n",
       "      <td>[TypeScript, JavaScript, Shell, CSS]</td>\n",
       "      <td>https://github.com/shadcn/taxonomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mattermost / focalboard</td>\n",
       "      <td>Focalboard is an open source, self-hosted alte...</td>\n",
       "      <td>228</td>\n",
       "      <td>[TypeScript, Go, SCSS, Makefile, Swift, C#]</td>\n",
       "      <td>https://github.com/mattermost/focalboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bluesky-social / atproto</td>\n",
       "      <td>A social networking technology created by Bluesky</td>\n",
       "      <td>11</td>\n",
       "      <td>[TypeScript, JavaScript]</td>\n",
       "      <td>https://github.com/bluesky-social/atproto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TheAlgorithms / Rust</td>\n",
       "      <td>All Algorithms implemented in Rust</td>\n",
       "      <td>142</td>\n",
       "      <td>[Rust]</td>\n",
       "      <td>https://github.com/TheAlgorithms/Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bradtraversy / 50projects50days</td>\n",
       "      <td>50+ mini web projects using HTML, CSS &amp; JS</td>\n",
       "      <td>35</td>\n",
       "      <td>[CSS, HTML, JavaScript]</td>\n",
       "      <td>https://github.com/bradtraversy/50projects50days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>folke / noice.nvim</td>\n",
       "      <td>💥 Highly experimental plugin that completely r...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Lua]</td>\n",
       "      <td>https://github.com/folke/noice.nvim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trimstray / the-book-of-secret-knowledge</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>100</td>\n",
       "      <td>[NA]</td>\n",
       "      <td>https://github.com/trimstray/the-book-of-secre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AMAI-GmbH / AI-Expert-Roadmap</td>\n",
       "      <td>Roadmap to becoming an Artificial Intelligence...</td>\n",
       "      <td>9</td>\n",
       "      <td>[JavaScript, Vue, Stylus]</td>\n",
       "      <td>https://github.com/AMAI-GmbH/AI-Expert-Roadmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AmazingAng / WTF-Solidity</td>\n",
       "      <td>我最近在重新学solidity，巩固一下细节，也写一个“WTF Solidity极简入门”，...</td>\n",
       "      <td>59</td>\n",
       "      <td>[Solidity]</td>\n",
       "      <td>https://github.com/AmazingAng/WTF-Solidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ripienaar / free-for-dev</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>1,275</td>\n",
       "      <td>[HTML]</td>\n",
       "      <td>https://github.com/ripienaar/free-for-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>4,598</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, Shell, Dockerfil...</td>\n",
       "      <td>https://github.com/freeCodeCamp/freeCodeCamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yyx990803 / vite-vs-next-turbo-hmr</td>\n",
       "      <td>Benchmarking Vite vs. Next + turbopack HMR per...</td>\n",
       "      <td>3</td>\n",
       "      <td>[JavaScript, CSS, HTML]</td>\n",
       "      <td>https://github.com/yyx990803/vite-vs-next-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PaddlePaddle / PaddleHub</td>\n",
       "      <td>Awesome pre-trained models toolkit based on Pa...</td>\n",
       "      <td>59</td>\n",
       "      <td>[Python]</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>neovim / nvim-lspconfig</td>\n",
       "      <td>Quickstart configs for Nvim LSP</td>\n",
       "      <td>381</td>\n",
       "      <td>[Lua]</td>\n",
       "      <td>https://github.com/neovim/nvim-lspconfig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jeecgboot / jeecg-boot</td>\n",
       "      <td>⭐️「企业级低代码平台」前后端分离架构SpringBoot 2.x，SpringCloud，...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Java, FreeMarker]</td>\n",
       "      <td>https://github.com/jeecgboot/jeecg-boot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title  \\\n",
       "Sr. No.                                             \n",
       "1                                    dudykr / stc   \n",
       "2                             charmbracelet / vhs   \n",
       "3                  simeydotme / pokemon-cards-css   \n",
       "4                                 ocornut / imgui   \n",
       "5                       acmesh-official / acme.sh   \n",
       "6                             mastodon / mastodon   \n",
       "7                    alvaroreis / bolsonaro2turno   \n",
       "8                         ossu / computer-science   \n",
       "9                 faridrashidi / kaggle-solutions   \n",
       "10                            jellyfin / jellyfin   \n",
       "11                              shadcn / taxonomy   \n",
       "12                        mattermost / focalboard   \n",
       "13                       bluesky-social / atproto   \n",
       "14                           TheAlgorithms / Rust   \n",
       "15                bradtraversy / 50projects50days   \n",
       "16                             folke / noice.nvim   \n",
       "17       trimstray / the-book-of-secret-knowledge   \n",
       "18                  AMAI-GmbH / AI-Expert-Roadmap   \n",
       "19                      AmazingAng / WTF-Solidity   \n",
       "20                       ripienaar / free-for-dev   \n",
       "21                    freeCodeCamp / freeCodeCamp   \n",
       "22             yyx990803 / vite-vs-next-turbo-hmr   \n",
       "23                       PaddlePaddle / PaddleHub   \n",
       "24                        neovim / nvim-lspconfig   \n",
       "25                         jeecgboot / jeecg-boot   \n",
       "\n",
       "                                               Description  Count  \\\n",
       "Sr. No.                                                             \n",
       "1                           Speedy TypeScript type checker      4   \n",
       "2                           Your CLI home video recorder 📼      8   \n",
       "3        A collection of advanced CSS styles to create ...      2   \n",
       "4        Dear ImGui: Bloat-free Graphical User interfac...    305   \n",
       "5        A pure Unix shell script implementing ACME cli...    407   \n",
       "6        Your self-hosted, globally interconnected micr...    687   \n",
       "7        Gere seu flyer personalizado com seu nome de a...     NA   \n",
       "8        🎓 Path to a free self-taught education in Comp...    126   \n",
       "9             🏅 Collection of Kaggle Solutions and Ideas 🏅      2   \n",
       "10                          The Free Software Media System    793   \n",
       "11       An open source application built using the new...     NA   \n",
       "12       Focalboard is an open source, self-hosted alte...    228   \n",
       "13       A social networking technology created by Bluesky     11   \n",
       "14                      All Algorithms implemented in Rust    142   \n",
       "15              50+ mini web projects using HTML, CSS & JS     35   \n",
       "16       💥 Highly experimental plugin that completely r...      8   \n",
       "17       A collection of inspiring lists, manuals, chea...    100   \n",
       "18       Roadmap to becoming an Artificial Intelligence...      9   \n",
       "19       我最近在重新学solidity，巩固一下细节，也写一个“WTF Solidity极简入门”，...     59   \n",
       "20       A list of SaaS, PaaS and IaaS offerings that h...  1,275   \n",
       "21       freeCodeCamp.org's open-source codebase and cu...  4,598   \n",
       "22       Benchmarking Vite vs. Next + turbopack HMR per...      3   \n",
       "23       Awesome pre-trained models toolkit based on Pa...     59   \n",
       "24                         Quickstart configs for Nvim LSP    381   \n",
       "25       ⭐️「企业级低代码平台」前后端分离架构SpringBoot 2.x，SpringCloud，...     11   \n",
       "\n",
       "                                                  Language  \\\n",
       "Sr. No.                                                      \n",
       "1                                                   [Rust]   \n",
       "2                                         [Go, Dockerfile]   \n",
       "3                          [Svelte, CSS, JavaScript, HTML]   \n",
       "4          [C++, C, Objective-C++, Objective-C, GLSL, GDB]   \n",
       "5                                      [Shell, Dockerfile]   \n",
       "6         [Ruby, JavaScript, SCSS, Haml, HTML, Dockerfile]   \n",
       "7                                  [HTML, JavaScript, CSS]   \n",
       "8                                                     [NA]   \n",
       "9                                                   [HTML]   \n",
       "10                                                    [C#]   \n",
       "11                    [TypeScript, JavaScript, Shell, CSS]   \n",
       "12             [TypeScript, Go, SCSS, Makefile, Swift, C#]   \n",
       "13                                [TypeScript, JavaScript]   \n",
       "14                                                  [Rust]   \n",
       "15                                 [CSS, HTML, JavaScript]   \n",
       "16                                                   [Lua]   \n",
       "17                                                    [NA]   \n",
       "18                               [JavaScript, Vue, Stylus]   \n",
       "19                                              [Solidity]   \n",
       "20                                                  [HTML]   \n",
       "21       [TypeScript, JavaScript, CSS, Shell, Dockerfil...   \n",
       "22                                 [JavaScript, CSS, HTML]   \n",
       "23                                                [Python]   \n",
       "24                                                   [Lua]   \n",
       "25                                      [Java, FreeMarker]   \n",
       "\n",
       "                                                       URL  \n",
       "Sr. No.                                                     \n",
       "1                            https://github.com/dudykr/stc  \n",
       "2                     https://github.com/charmbracelet/vhs  \n",
       "3          https://github.com/simeydotme/pokemon-cards-css  \n",
       "4                         https://github.com/ocornut/imgui  \n",
       "5               https://github.com/acmesh-official/acme.sh  \n",
       "6                     https://github.com/mastodon/mastodon  \n",
       "7            https://github.com/alvaroreis/bolsonaro2turno  \n",
       "8                 https://github.com/ossu/computer-science  \n",
       "9         https://github.com/faridrashidi/kaggle-solutions  \n",
       "10                    https://github.com/jellyfin/jellyfin  \n",
       "11                      https://github.com/shadcn/taxonomy  \n",
       "12                https://github.com/mattermost/focalboard  \n",
       "13               https://github.com/bluesky-social/atproto  \n",
       "14                   https://github.com/TheAlgorithms/Rust  \n",
       "15        https://github.com/bradtraversy/50projects50days  \n",
       "16                     https://github.com/folke/noice.nvim  \n",
       "17       https://github.com/trimstray/the-book-of-secre...  \n",
       "18          https://github.com/AMAI-GmbH/AI-Expert-Roadmap  \n",
       "19              https://github.com/AmazingAng/WTF-Solidity  \n",
       "20               https://github.com/ripienaar/free-for-dev  \n",
       "21            https://github.com/freeCodeCamp/freeCodeCamp  \n",
       "22       https://github.com/yyx990803/vite-vs-next-turb...  \n",
       "23               https://github.com/PaddlePaddle/PaddleHub  \n",
       "24                https://github.com/neovim/nvim-lspconfig  \n",
       "25                 https://github.com/jeecgboot/jeecg-boot  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(title,description,count,language,url ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Title', 'Description', 'Count','Language','URL'],\n",
    "                  index=pd.RangeIndex(start=1, stop=26, name='Sr. No.'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of trending repositories on Github.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b7747",
   "metadata": {},
   "source": [
    "\n",
    "Q 6. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank \n",
    "\n",
    "D) Peak rank \n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92f49af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28acf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\" https:/www.billboard.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b23c4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on button tab\n",
    "\n",
    "button =driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "driver.get(button.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06340e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on hot100 tab\n",
    "\n",
    "hot100 =driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a')\n",
    "driver.get(hot100.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a40034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped datas\n",
    "\n",
    "name =[]\n",
    "artist =[]\n",
    "rank=[]\n",
    "peak_rank =[]\n",
    "weeks =[]\n",
    "all_info=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36376857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song Name\n",
    "try:\n",
    "    song_tags =driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/h3')\n",
    "    for i in song_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78e77f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2719a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info=[]\n",
    "try:\n",
    "    all_tags =driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/span')\n",
    "    for i in all_tags:\n",
    "        all_info.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    all_info.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cfa6f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping artist\n",
    "artist= all_info[0:401:4]\n",
    "len(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f9587b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rank\n",
    "rank= all_info[1:401:4]\n",
    "len(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df2ab046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rank\n",
    "peak_rank= all_info[2:401:4]\n",
    "len(peak_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45441e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping weeks\n",
    "weeks= all_info[3:401:4]\n",
    "len(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0441eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of top 100 songs on billiboard.com.:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This_week_rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad Habit</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California Breeze</td>\n",
       "      <td>Lil Baby</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I Like You (A Happier Song)</td>\n",
       "      <td>Post Malone Featuring Doja Cat</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Static</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 52</td>\n",
       "      <td>Bizarrap &amp; Quevedo</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Lee Brice</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Forget Me</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Good Love</td>\n",
       "      <td>City Girls &amp; Usher</td>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Song_name                     Artist_name  \\\n",
       "This_week_rank                                                                 \n",
       "1                                     Unholy          Sam Smith & Kim Petras   \n",
       "2                                  Bad Habit                      Steve Lacy   \n",
       "3                                  As It Was                    Harry Styles   \n",
       "4                          California Breeze                        Lil Baby   \n",
       "5                I Like You (A Happier Song)  Post Malone Featuring Doja Cat   \n",
       "...                                      ...                             ...   \n",
       "96                                    Static                      Steve Lacy   \n",
       "97              Bzrp Music Sessions, Vol. 52              Bizarrap & Quevedo   \n",
       "98                                      Soul                       Lee Brice   \n",
       "99                                 Forget Me                   Lewis Capaldi   \n",
       "100                                Good Love              City Girls & Usher   \n",
       "\n",
       "               Last_week_rank Peak_rank Weeks on board  \n",
       "This_week_rank                                          \n",
       "1                           2         1              4  \n",
       "2                           1         1             16  \n",
       "3                           3         1             29  \n",
       "4                           -         4              1  \n",
       "5                           4         3             20  \n",
       "...                       ...       ...            ...  \n",
       "96                         84        78              7  \n",
       "97                         79        79              9  \n",
       "98                         85        83              6  \n",
       "99                         95        95              3  \n",
       "100                        86        70              5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,artist,rank,peak_rank,weeks ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Song_name', 'Artist_name', 'Last_week_rank','Peak_rank','Weeks on board'],\n",
    "                  index=pd.RangeIndex(start=1, stop=101, name='This_week_rank'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of top 100 songs on billiboard.com.:\\n\")\n",
    "data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c7797",
   "metadata": {},
   "source": [
    "\n",
    "Q7.Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/. You have to find the following details\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company \n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa072bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7def3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/data-science-recruiters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e1da0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped datas\n",
    "name=[] \n",
    "designation=[] \n",
    "company=[] \n",
    "skills=[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5826a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping name\n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "    for i in name_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afe607d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc873d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping designation\n",
    "try:\n",
    "    des_tags =driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "    for i in des_tags:\n",
    "        designation.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    designation.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c10418c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(designation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f99a0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping company\n",
    "comp=[]\n",
    "try:\n",
    "    com_tags =driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]')\n",
    "    for i in com_tags:\n",
    "        comp.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    comp.append('NA')\n",
    "    \n",
    "for i in range(0, len(comp)):\n",
    "    if i %2==1:\n",
    "        company.append(comp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e41d93c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(company)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ff275dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scraping skills\n",
    "try:\n",
    "    skills_tags =driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "    for i in skills_tags:\n",
    "        skills.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    skills.append('NA')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e525362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfd4f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping url\n",
    "try:\n",
    "    url_tags =driver.find_elements(By.XPATH,'//div[@class=\"recImg mid_pImg_Silht\"]/a')\n",
    "    for i in url_tags:\n",
    "        url.append(i.get_attribute(\"href\"))\n",
    "except NoSuchElementException:\n",
    "    url.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "658e2120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "888a8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of Data science recruiters from naukri.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>https://www.naukri.com/recruiters/aakashharit-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>https://www.naukri.com/recruiters/shravankumar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>https://www.naukri.com/recruiters/marsiantech?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>https://www.naukri.com/recruiters/anikagrawal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>https://www.naukri.com/recruiters/LXP-DATASCIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>https://www.naukri.com/recruiters/abhishekyada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>https://www.naukri.com/recruiters/menakav-3213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>https://www.naukri.com/recruiters/techvantage?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>https://www.naukri.com/recruiters/asiflucknowi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>https://www.naukri.com/recruiters/instafinanci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "      <td>https://www.naukri.com/recruiters/priyankaakir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>https://www.naukri.com/recruiters/kalpana-2078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>https://www.naukri.com/recruiters/mubarak-2905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>https://www.naukri.com/recruiters/quantmagnum?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>https://www.naukri.com/recruiters/maheshbabuch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "      <td>https://www.naukri.com/recruiters/vaishnavikud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>https://www.naukri.com/recruiters/kapildevang-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "      <td>https://www.naukri.com/recruiters/sakshichhika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "      <td>https://www.naukri.com/recruiters/ruchidhote?x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>https://www.naukri.com/recruiters/manishayadav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>https://www.naukri.com/recruiters/riyarajesh-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "      <td>https://www.naukri.com/recruiters/rashmibhatta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "      <td>https://www.naukri.com/recruiters/faizankareem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "      <td>https://www.naukri.com/recruiters/rithikadadwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "      <td>https://www.naukri.com/recruiters/ankitshah-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "      <td>https://www.naukri.com/recruiters/shaunrao-302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>https://www.naukri.com/recruiters/azaharshaikh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "      <td>https://www.naukri.com/recruiters/manas-315903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "      <td>https://www.naukri.com/recruiters/kumar-337889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "      <td>https://www.naukri.com/recruiters/sunilvedula-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "      <td>https://www.naukri.com/recruiters/rajatkumar-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "      <td>https://www.naukri.com/recruiters/dhruvdevdube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>https://www.naukri.com/recruiters/jayanthn-308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "      <td>https://www.naukri.com/recruiters/nikithapalap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "      <td>https://www.naukri.com/recruiters/sreedhar-382...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ravi Dubey</td>\n",
       "      <td>Recruitment Manager</td>\n",
       "      <td>HyrEzy Talent Solutions LLP</td>\n",
       "      <td>Walmart Interra Skeps Expressstores indifi whi...</td>\n",
       "      <td>https://www.naukri.com/recruiters/priyaranjanm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "      <td>https://www.naukri.com/recruiters/priyakhare-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "      <td>https://www.naukri.com/recruiters/amitsharma-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "      <td>https://www.naukri.com/recruiters/deepali002g?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "      <td>https://www.naukri.com/recruiters/shashikantch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "      <td>https://www.naukri.com/recruiters/brad-4068508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "      <td>https://www.naukri.com/recruiters/rutujapawar?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "      <td>https://www.naukri.com/recruiters/madhusudhans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "      <td>https://www.naukri.com/recruiters/ankitsinha-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "      <td>https://www.naukri.com/recruiters/gauravchouha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "      <td>https://www.naukri.com/recruiters/impel?xid=16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "      <td>https://www.naukri.com/recruiters/ashwini-3434...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "      <td>https://www.naukri.com/recruiters/balajikolli-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "      <td>https://www.naukri.com/recruiters/rajaninagara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "      <td>https://www.naukri.com/recruiters/rohitkumar-3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "Sr No                                                  \n",
       "1                                       Aakash Harit   \n",
       "2                               shravan Kumar Gaddam   \n",
       "3                           MARSIAN Technologies LLP   \n",
       "4                                       Anik Agrawal   \n",
       "5                                       subhas patel   \n",
       "6       Abhishek - Only Analytics Hiring - India and   \n",
       "7      Institute for Financial Management and Resear   \n",
       "8                                        Balu Ramesh   \n",
       "9                                      Asif Lucknowi   \n",
       "10                                   InstaFinancials   \n",
       "11                                    Priyanka Akiri   \n",
       "12                                   Kalpana Dumpala   \n",
       "13                                           Mubarak   \n",
       "14                                    Kushal Rastogi   \n",
       "15                                Mahesh Babu Channa   \n",
       "16                                Vaishnavi Kudalkar   \n",
       "17                                      Kapil Devang   \n",
       "18                                   Sakshi Chhikara   \n",
       "19                                       Ruchi Dhote   \n",
       "20                                     Manisha Yadav   \n",
       "21                                       Riya Rajesh   \n",
       "22                              Rashmi Bhattacharjee   \n",
       "23                                     Faizan Kareem   \n",
       "24                                    Rithika dadwal   \n",
       "25                                Sandhya Khandagale   \n",
       "26                                         Shaun Rao   \n",
       "27                                     Azahar Shaikh   \n",
       "28                                             Manas   \n",
       "29                                             kumar   \n",
       "30                                      Sunil Vedula   \n",
       "31                                       Rajat Kumar   \n",
       "32                                   Dhruv Dev Dubey   \n",
       "33                                         Jayanth N   \n",
       "34                                            Avodha   \n",
       "35                                          SREEDHAR   \n",
       "36                                        Ravi Dubey   \n",
       "37                                       Priya Khare   \n",
       "38                                       Amit Sharma   \n",
       "39                                             Kanan   \n",
       "40                              Shashikant Chaudhary   \n",
       "41                                              Brad   \n",
       "42                                      Rutuja Pawar   \n",
       "43                               Madhusudhan Sridhar   \n",
       "44                                       Ankit Sinha   \n",
       "45                                    Gaurav Chouhan   \n",
       "46                                      Rashi Kacker   \n",
       "47                                           Ashwini   \n",
       "48                                      Balaji Kolli   \n",
       "49                                    Rajani Nagaraj   \n",
       "50                                       ROHIT Kumar   \n",
       "\n",
       "                               Designation  \\\n",
       "Sr No                                        \n",
       "1                               HR Manager   \n",
       "2                        Company Recruiter   \n",
       "3                               Company HR   \n",
       "4                        Company Recruiter   \n",
       "5                              Founder CEO   \n",
       "6              Recruitment Lead Consultant   \n",
       "7                        Programme Manager   \n",
       "8                         HR Administrator   \n",
       "9                                 Director   \n",
       "10                          Human Resource   \n",
       "11                              HR Manager   \n",
       "12                        Executive Hiring   \n",
       "13                              Company HR   \n",
       "14                              Company HR   \n",
       "15                            HR Team Lead   \n",
       "16                            HR Executive   \n",
       "17                              HR Manager   \n",
       "18                    Assistant Manager HR   \n",
       "19     Senior Executive Talent Acquisition   \n",
       "20                            HR Executive   \n",
       "21              Manager Talent Acquisition   \n",
       "22                                 HR Head   \n",
       "23                              HR MANAGER   \n",
       "24                            HR Recruiter   \n",
       "25                            HR Recruiter   \n",
       "26                 Manager Human Resources   \n",
       "27                       Company Recruiter   \n",
       "28                 Lead Talent acquisition   \n",
       "29                              Proprietor   \n",
       "30                                     CEO   \n",
       "31                             Founder CEO   \n",
       "32                Company Recruitment Head   \n",
       "33                         Project Manager   \n",
       "34          Business Development Associate   \n",
       "35                  Recruitment Consultant   \n",
       "36                     Recruitment Manager   \n",
       "37                          Senior Manager   \n",
       "38                              Consultant   \n",
       "39            senior technology instructor   \n",
       "40                HR Recruiter/HR Excutive   \n",
       "41           Manager, Technical Recruiting   \n",
       "42                     Technical Recruiter   \n",
       "43                         Erp Implementer   \n",
       "44                          Head Analytics   \n",
       "45                 Chief Technical Officer   \n",
       "46                      Sr Product Manager   \n",
       "47                Director Global Delivery   \n",
       "48                              Co Founder   \n",
       "49                              HR Manager   \n",
       "50                               Architect   \n",
       "\n",
       "                                              Company  \\\n",
       "Sr No                                                   \n",
       "1                                Data Science Network   \n",
       "2                       Shore Infotech India Pvt. Ltd   \n",
       "3                            MARSIAN Technologies LLP   \n",
       "4               Enerlytics Software Solutions Pvt Ltd   \n",
       "5                                     LibraryXProject   \n",
       "6          Apidel Technologies Division of Transpower   \n",
       "7                                                IFMR   \n",
       "8                         Techvantage Systems Pvt Ltd   \n",
       "9                          Weupskill- Live Wire India   \n",
       "10                   CBL Data Science Private Limited   \n",
       "11                      Infinitive Software Solutions   \n",
       "12                                 Innominds Software   \n",
       "13                                           MoneyTap   \n",
       "14                 QuantMagnum Technologies Pvt. Ltd.   \n",
       "15                                  SocialPrachar.com   \n",
       "16                                Codeachive learning   \n",
       "17                                     BISP Solutions   \n",
       "18                      BIZ INFOTECNO PRIVATE LIMITED   \n",
       "19                              Bristlecone India Ltd   \n",
       "20                                           Easi Tax   \n",
       "21                        Novelworx Digital Solutions   \n",
       "22            AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "23                      FirstTech Consaltants Pvt.Ltd   \n",
       "24                                   Affine Analytics   \n",
       "25                    Compumatrice Multimedia Pvt Ltd   \n",
       "26                                 Exela Technologies   \n",
       "27                    NEAL ANALYTICS SERVICES PVT LTD   \n",
       "28         Autumn Leaf Consulting Services Private...   \n",
       "29                                            trainin   \n",
       "30                               Nanoprecise Sci Corp   \n",
       "31                     R.S Consultancy &amp; Services   \n",
       "32                                       Confidential   \n",
       "33           Dollarbird Information Services Pvt, Ltd   \n",
       "34                                 Nikitha Palaparthi   \n",
       "35        JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "36                        HyrEzy Talent Solutions LLP   \n",
       "37                             Independent Consultant   \n",
       "38                                    ASCO consulting   \n",
       "39                                            NY INST   \n",
       "40     3D India Staffing Research &amp; Consulting...   \n",
       "41                                        O.C. Tanner   \n",
       "42                                      Demand Matrix   \n",
       "43                                MADHUSUDHAN SRIDHAR   \n",
       "44                                     Suntech Global   \n",
       "45                           Strategic Consulting Lab   \n",
       "46                               Impel Labs Pvt. Ltd.   \n",
       "47                                       MRP Advisers   \n",
       "48                      Saras Solutions India Pvt Ltd   \n",
       "49                                        WildJasmine   \n",
       "50                                LNT Private Limited   \n",
       "\n",
       "                                                  Skills  \\\n",
       "Sr No                                                      \n",
       "1      Classic ASP Developer, Internet Marketing Prof...   \n",
       "2      .Net, Java, Data Science, Linux Administration...   \n",
       "3      Data Science, Artificial Intelligence, Machine...   \n",
       "4      Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "5      Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "6      Analytics, Business Intelligence, Business Ana...   \n",
       "7                                           Data Science   \n",
       "8      Machine Learning, algorithms, Go Getter, Compu...   \n",
       "9      Technical Training, Software Development, Pres...   \n",
       "10     Software Development, It Sales, Account Manage...   \n",
       "11     Oracle Dba, Data Science, Data Warehousing, ET...   \n",
       "12     Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
       "13     Business Intelligence, Data Warehousing, Data ...   \n",
       "14     Office Administration, Hr Administration, tele...   \n",
       "15     Social Media, digital media maketing, seo, smm...   \n",
       "16                  Data Science, Python, Data Analytics   \n",
       "17        Big Data, Hadoop, Data Analytics, Data Science   \n",
       "18     React.js, Data Science, Java, Front End, Busin...   \n",
       "19     Qlikview, Qlik Sense, Microsoft Azure, Power B...   \n",
       "20     Telecalling, Client Interaction, Marketing, Re...   \n",
       "21                                          Data Science   \n",
       "22     Corporate Sales, Software Development, Softwar...   \n",
       "23     Data Analytics, Data Science, Machine Learning...   \n",
       "24     Data Science, Machine Learning, Python, R, Dee...   \n",
       "25     Big Data, Data Science, Artificial Intelligenc...   \n",
       "26     Java, Net, Angularjs, Hr, Infrastructure, Mana...   \n",
       "27     Data Science, Artificial Intelligence, Machine...   \n",
       "28     Software Architecture, Vp Engineering, Product...   \n",
       "29     Data Science, Hadoop, Rpas, Devops, Python, Aw...   \n",
       "30     Signal Processing, Machine Learning, Neural Ne...   \n",
       "31     Web Technologies, Project Management, Software...   \n",
       "32     Server Administartion, Verilog, Vhdl, Digital ...   \n",
       "33     Data Analytics, Managed Services, Team Leading...   \n",
       "34     Ethical Hacking, Security Operations Center, S...   \n",
       "35     Data Science, Machine Learning, Big Data Analy...   \n",
       "36     Walmart Interra Skeps Expressstores indifi whi...   \n",
       "37     Data Science, Artificial Intelligence, analyti...   \n",
       "38     Machine Learning, Artificial Intelligence, Dat...   \n",
       "39     C, C++, Artificial Intelligence, Python, Php, ...   \n",
       "40     Relationship Management, Retail Sales, Private...   \n",
       "41                    Data Science, Software Engineering   \n",
       "42     Data Science, Big Data Analytics, Digital Mark...   \n",
       "43                     Data Science, Recruitment, Salary   \n",
       "44     B.Tech, Tableau, Statistics, R, Analytics, Tim...   \n",
       "45     Software Development, Business Intelligence, B...   \n",
       "46                      Data Science, Node.js, Angularjs   \n",
       "47     Data Science, Media Marketing, Resource Planni...   \n",
       "48     Data Analysis, Learning, Data Science, Compute...   \n",
       "49     Java, Hadoop, R, Machine Learning, Spark, Flum...   \n",
       "50     Software Development, Core Java, Unit Testing,...   \n",
       "\n",
       "                                                     URL  \n",
       "Sr No                                                     \n",
       "1      https://www.naukri.com/recruiters/aakashharit-...  \n",
       "2      https://www.naukri.com/recruiters/shravankumar...  \n",
       "3      https://www.naukri.com/recruiters/marsiantech?...  \n",
       "4      https://www.naukri.com/recruiters/anikagrawal-...  \n",
       "5      https://www.naukri.com/recruiters/LXP-DATASCIE...  \n",
       "6      https://www.naukri.com/recruiters/abhishekyada...  \n",
       "7      https://www.naukri.com/recruiters/menakav-3213...  \n",
       "8      https://www.naukri.com/recruiters/techvantage?...  \n",
       "9      https://www.naukri.com/recruiters/asiflucknowi...  \n",
       "10     https://www.naukri.com/recruiters/instafinanci...  \n",
       "11     https://www.naukri.com/recruiters/priyankaakir...  \n",
       "12     https://www.naukri.com/recruiters/kalpana-2078...  \n",
       "13     https://www.naukri.com/recruiters/mubarak-2905...  \n",
       "14     https://www.naukri.com/recruiters/quantmagnum?...  \n",
       "15     https://www.naukri.com/recruiters/maheshbabuch...  \n",
       "16     https://www.naukri.com/recruiters/vaishnavikud...  \n",
       "17     https://www.naukri.com/recruiters/kapildevang-...  \n",
       "18     https://www.naukri.com/recruiters/sakshichhika...  \n",
       "19     https://www.naukri.com/recruiters/ruchidhote?x...  \n",
       "20     https://www.naukri.com/recruiters/manishayadav...  \n",
       "21     https://www.naukri.com/recruiters/riyarajesh-4...  \n",
       "22     https://www.naukri.com/recruiters/rashmibhatta...  \n",
       "23     https://www.naukri.com/recruiters/faizankareem...  \n",
       "24     https://www.naukri.com/recruiters/rithikadadwa...  \n",
       "25     https://www.naukri.com/recruiters/ankitshah-21...  \n",
       "26     https://www.naukri.com/recruiters/shaunrao-302...  \n",
       "27     https://www.naukri.com/recruiters/azaharshaikh...  \n",
       "28     https://www.naukri.com/recruiters/manas-315903...  \n",
       "29     https://www.naukri.com/recruiters/kumar-337889...  \n",
       "30     https://www.naukri.com/recruiters/sunilvedula-...  \n",
       "31     https://www.naukri.com/recruiters/rajatkumar-3...  \n",
       "32     https://www.naukri.com/recruiters/dhruvdevdube...  \n",
       "33     https://www.naukri.com/recruiters/jayanthn-308...  \n",
       "34     https://www.naukri.com/recruiters/nikithapalap...  \n",
       "35     https://www.naukri.com/recruiters/sreedhar-382...  \n",
       "36     https://www.naukri.com/recruiters/priyaranjanm...  \n",
       "37     https://www.naukri.com/recruiters/priyakhare-4...  \n",
       "38     https://www.naukri.com/recruiters/amitsharma-4...  \n",
       "39     https://www.naukri.com/recruiters/deepali002g?...  \n",
       "40     https://www.naukri.com/recruiters/shashikantch...  \n",
       "41     https://www.naukri.com/recruiters/brad-4068508...  \n",
       "42     https://www.naukri.com/recruiters/rutujapawar?...  \n",
       "43     https://www.naukri.com/recruiters/madhusudhans...  \n",
       "44     https://www.naukri.com/recruiters/ankitsinha-3...  \n",
       "45     https://www.naukri.com/recruiters/gauravchouha...  \n",
       "46     https://www.naukri.com/recruiters/impel?xid=16...  \n",
       "47     https://www.naukri.com/recruiters/ashwini-3434...  \n",
       "48     https://www.naukri.com/recruiters/balajikolli-...  \n",
       "49     https://www.naukri.com/recruiters/rajaninagara...  \n",
       "50     https://www.naukri.com/recruiters/rohitkumar-3...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,designation,company,skills,url))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Name', 'Designation', 'Company','Skills','URL'],\n",
    "                  index=pd.RangeIndex(start=1, stop=51, name='Sr No'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of Data science recruiters from naukri.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5f2b8",
   "metadata": {},
   "source": [
    "Q8. Scrape the details of Highest selling novels. Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey%02compare/ You have to find the following details: A) Book name B) Author name C) Volumes sold D) Publisher E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab449514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1992151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"  https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53886627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists for scrapped data\n",
    "\n",
    "book =[]\n",
    "author =[]\n",
    "volumes_sold =[]\n",
    "publisher =[]\n",
    "genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f446a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book_tags:\n",
    "        book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    book.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "946c0249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(book)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98c08a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book author's\n",
    "try:\n",
    "    author_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    author.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ec2284c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(author)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5e66c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Volumes sold\n",
    "try:\n",
    "    volumes_sold_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in volumes_sold_tags :\n",
    "        volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f45e418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(volumes_sold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfd0fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping publisher\n",
    "try:\n",
    "    publisher_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher_tags :\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    publisher.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "929d6575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(publisher)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d373737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scraping genre\n",
    "try:\n",
    "    genre_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre_tags :\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a18768f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(genre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ce623dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of Highest selling novels.:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Book_ Author</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Book      Book_ Author  \\\n",
       "Rank                                                                        \n",
       "1                                     Da Vinci Code,The        Brown, Dan   \n",
       "2                  Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3              Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4             Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                  Fifty Shades of Grey      James, E. L.   \n",
       "...                                                 ...               ...   \n",
       "96                                            Ghost,The    Harris, Robert   \n",
       "97                       Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98                Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99    Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100   Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "     Volumes_Sold        Publisher                        Genre  \n",
       "Rank                                                             \n",
       "1       5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2       4,475,152       Bloomsbury           Children's Fiction  \n",
       "3       4,200,654       Bloomsbury           Children's Fiction  \n",
       "4       4,179,479       Bloomsbury           Children's Fiction  \n",
       "5       3,758,936     Random House              Romance & Sagas  \n",
       "...           ...              ...                          ...  \n",
       "96        807,311     Random House   General & Literary Fiction  \n",
       "97        794,201          Penguin        Food & Drink: General  \n",
       "98        792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99        791,507            Orion           Biography: General  \n",
       "100       791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(book,author,volumes_sold,publisher,genre ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Book', 'Book_ Author', 'Volumes_Sold','Publisher','Genre'],\n",
    "                  index=pd.RangeIndex(start=1, stop=101, name='Rank'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of Highest selling novels.:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ee2ec",
   "metadata": {},
   "source": [
    "Q9.Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03e6b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df2a2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\" https://www.imdb.com/list/ls095964455/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90cc4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped data\n",
    "\n",
    "name =[]\n",
    "year=[]\n",
    "genre =[]\n",
    "run_time =[]\n",
    "ratings =[]\n",
    "votes =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d645c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name \n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "    \n",
    "# Scraping Year span\n",
    "try:\n",
    "    year_tags =driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year_tags :\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre_tags =driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in genre_tags :\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')\n",
    "    \n",
    "# Scraping Run Time \n",
    "try:\n",
    "    run_time_tags =driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in run_time_tags :\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    run_time.append('NA')\n",
    "    \n",
    "# Scraping Ratings\n",
    "try:\n",
    "    ratings_tags =driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings_tags :\n",
    "        ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ratings.append('NA')\n",
    "\n",
    "# Scraping Votes\n",
    "try:\n",
    "    votes_tags =driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in votes_tags :\n",
    "        votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5c8994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(len(name))\n",
    "print(len(genre))\n",
    "print(len(year))\n",
    "print(len(run_time))\n",
    "print(len(ratings))\n",
    "print(len(votes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8500ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of most watched tv series of all time from imdb.com. :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,075,452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,166,220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>978,011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>291,213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>250,347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>196,404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>241,848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name    Year span                     Genre  \\\n",
       "Rank                                                                          \n",
       "1                    Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "2                    Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "3                   The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "4                     13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "5                            The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "...                              ...          ...                       ...   \n",
       "96                             Reign  (2013–2017)                     Drama   \n",
       "97    A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "98                    Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "99             Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "100       The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Run_Time Ratings      Votes  \n",
       "Rank                              \n",
       "1      57 min     9.2  2,075,452  \n",
       "2      51 min     8.7  1,166,220  \n",
       "3      44 min     8.1    978,011  \n",
       "4      60 min     7.5    291,213  \n",
       "5      43 min     7.6    250,347  \n",
       "...       ...     ...        ...  \n",
       "96     42 min     7.4     49,910  \n",
       "97     50 min     7.8     61,020  \n",
       "98     42 min     8.1    196,404  \n",
       "99     45 min     7.1     41,373  \n",
       "100   572 min     8.6    241,848  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,year,genre,run_time,ratings,votes ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Name','Year span','Genre', 'Run_Time','Ratings','Votes'],\n",
    "                  index=pd.RangeIndex(start=1, stop=101, name='Rank'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of most watched tv series of all time from imdb.com. :\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb7c3a",
   "metadata": {},
   "source": [
    "\n",
    "Q10. Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details: A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year Note: - from the home page you have to go to the ShowAllDataset page through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0faf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,InvalidArgumentException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ea0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\sahal\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34339d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening site\n",
    "driver.get(\"https://archive.ics.uci.edu/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd5e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on all dataset\n",
    "driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f48d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping url of dataset\n",
    "url = []\n",
    "for i in driver.find_elements(By.XPATH,'//b/a'):\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b30771",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attribute = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4420635",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in url:\n",
    "    driver.get(u)\n",
    "    time.sleep(1)\n",
    "# Extracting Dataset_name \n",
    "    try:\n",
    "        dn = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[1]/tbody/tr/td[1]/p[1]/span[1]/b')      \n",
    "        Dataset_name.append(dn.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')    \n",
    "# extracting Data_type\n",
    "    try:\n",
    "        dt = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p')\n",
    "        Data_type.append(dt.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "# extracting Task\n",
    "    try:\n",
    "        t = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[3]/td[2]/p')\n",
    "        Task.append(t.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')  \n",
    "# extracting Attribute_type\n",
    "    try:\n",
    "        at = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[2]/p')\n",
    "        Attribute_type.append(at.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')        \n",
    "# extracting No_of_instances\n",
    "    try:\n",
    "        ni = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[4]/p')\n",
    "        No_of_instances.append(ni.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')       \n",
    "# extracting No_of_attribute\n",
    "    try:\n",
    "        na = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[4]/p')\n",
    "        No_of_attribute.append(na.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attribute.append('-')    \n",
    "# extracting Year \n",
    "    try:\n",
    "        y = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[6]/p')\n",
    "        Year.append(y.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412442ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets from UCI machine learning repositories\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>extracting Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annealing Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous Microsoft Web Data Data Set</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arrhythmia Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Turkish Music Emotion Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Maternal Health Risk Data Set Data Set</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Room Occupancy Estimation Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate, Sequential, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "1                                     Abalone Data Set   \n",
       "2                                       Adult Data Set   \n",
       "3                                   Annealing Data Set   \n",
       "4                Anonymous Microsoft Web Data Data Set   \n",
       "5                                  Arrhythmia Data Set   \n",
       "..                                                 ...   \n",
       "618  Influenza outbreak event prediction via Twitte...   \n",
       "619             Turkish Music Emotion Dataset Data Set   \n",
       "620             Maternal Health Risk Data Set Data Set   \n",
       "621                 Room Occupancy Estimation Data Set   \n",
       "622  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                               Data_type                 Task  \\\n",
       "1                           Multivariate       Classification   \n",
       "2                           Multivariate       Classification   \n",
       "3                           Multivariate       Classification   \n",
       "4                                    N/A  Recommender-Systems   \n",
       "5                           Multivariate       Classification   \n",
       "..                                   ...                  ...   \n",
       "618                         Multivariate       Classification   \n",
       "619                         Multivariate       Classification   \n",
       "620                                  N/A       Classification   \n",
       "621            Multivariate, Time-Series       Classification   \n",
       "622  Univariate, Sequential, Time-Series           Regression   \n",
       "\n",
       "                 Attribute_type No_of_instances No_of_attribute  \\\n",
       "1    Categorical, Integer, Real            4177               8   \n",
       "2          Categorical, Integer           48842              14   \n",
       "3    Categorical, Integer, Real             798              38   \n",
       "4                   Categorical           37711             294   \n",
       "5    Categorical, Integer, Real             452             279   \n",
       "..                          ...             ...             ...   \n",
       "618               Integer, Real           75840             525   \n",
       "619               Integer, Real             400              50   \n",
       "620                         N/A            1014               7   \n",
       "621                        Real           10129              16   \n",
       "622                        Real            4000               2   \n",
       "\n",
       "    extracting Year  \n",
       "1        1995-12-01  \n",
       "2        1996-05-01  \n",
       "3               N/A  \n",
       "4        1998-11-01  \n",
       "5        1998-01-01  \n",
       "..              ...  \n",
       "618      2020-12-16  \n",
       "619      2020-12-20  \n",
       "620      2020-12-31  \n",
       "621      2021-01-16  \n",
       "622      2020-12-13  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe \n",
    "df = pd.DataFrame({\"Dataset_name\":Dataset_name,\"Data_type\":Data_type,\"Task\":Task,\"Attribute_type\":Attribute_type,\"No_of_instances\":No_of_instances,\"No_of_attribute\":No_of_attribute,\"extracting Year\":Year},index=list(range(1,len(Year)+1)))\n",
    "print(\"Datasets from UCI machine learning repositories\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342790e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a0cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d715bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3472c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
